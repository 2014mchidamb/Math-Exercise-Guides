\section{Differentiation}

\subsection{Basic Definitions}

\subsubsection{Exercise 1}
Let the derivative of $f$ at $a$ be the linear operator $\lambda$. Then, by problem $1-10$, we have that
$\abs{\lambda(h)} \leq M \abs{h}$ for some $M \in \mathbb{R}$. Thus,
\begin{align*}
        \abs{(f(a + h) - f(a)} &= \frac{\abs{f(a + h) - f(a)}}{\abs{h}} * \abs{h} \\
                               &\leq \frac{\abs{f(a + h) - f(a) - \lambda(h)} + \abs{\lambda(h)}}{\abs{h}} * \abs{h} \\
        \implies \lim_{h \to 0} \abs{f(a + h) - f(a)} &\leq \lim_{h \to 0} \frac{\abs{f(a + h) - f(a) - \lambda(h)} + \abs{\lambda(h)}}{\abs{h}} \lim_{h \to 0} \abs{h} \\
                                                      &\leq M * 0 = 0
\end{align*}

\subsubsection{Exercise 2}
If $f$ is independent, we can define $g = f(x, y_0)$ for some arbitrary $y_0$. If there exists $g$ such that
$f(x, y) = g(x)$ for all $x, y$, then we have $f(x, y_1) = g(x) = f(x, y_2)$ so $f$ is independent of the
second variable. In this case, $f'(a, b) = g'(a)$.

\subsubsection{Exercise 3}
A function that is independent of both variables must, by construction, be constant.

\subsubsection{Exercise 4}
(a) When $t < 0$, we have
\begin{align*}
        h(t) = -t\abs{x} g\bigg(\frac{tx}{-t \abs{x}}\bigg) = t\abs{x}g\bigg(\frac{x}{\abs{x}}\bigg)
\end{align*}
which is the same as $h(t)$ when $t > 0$, so $h(t)$ is differentiable with derivative $f(x)$.

(b) Since $g(0, 1) = g(1, 0) = 0$, we have that $f(h, 0) = f(0, k) = 0$. Letting $\lambda = Df(0, 0)$, we have
that
\begin{align*}
        \lim_{(h, 0) \to 0} \frac{\abs{\lambda(h, 0)}}{\abs{h}} &= \lim_{(h, 0) \to 0} \frac{\abs{h} \lambda(1, 0)}{\abs{h}} \\
                                                                &= \lambda(1, 0) = 0
\end{align*}
if $\lambda$ exists. Similarly, considering $(0, k) \to 0$ gives $\lambda(0, 1) = 0$, so $\lambda = 0$. 
As a result, we have that $f$ is differentiable at $(0, 0)$ only if
\begin{align*}
        \lim_{(h, k) \to (0, 0)} \frac{\abs{f(h, k)}}{\abs{(h, k)}} = \lim_{(h, k) \to (0, 0)} \abs{g\bigg(\frac{(h, k)}{\abs{(h, k)}}\bigg)} = 0
\end{align*}
which implies that $g = 0$ (we can consider $t(x, y)$ as $t \to 0$ for every $(x, y)$ on the unit circle). 

\subsubsection{Exercise 5}
Apply the previous exercise with $g(x, y) = x\abs{y}$.

\subsubsection{Exercise 8}
If $f$ is differentiable, then
\begin{align*}
        \lim_{h \to 0} \frac{\abs{f(a + h) - f(a) - \lambda(h)}}{\abs{h}} &= 0 \\
                                                                          &= \lim_{h \to 0} \frac{\abs{(f_1(a + h) - f_1(a) - \lambda_1(h), f_2(a + h) - f_2(a) - \lambda_2(h))}}{\abs{h}} \\
                                                                          &\geq \lim_{h \to 0} \frac{\abs{f_1(a + h) - f_1(a) - \lambda_1(h)}}{\abs{h}}
\end{align*}
so $f_1$ and $f_2$ are both differentiable. The reverse direction is a straightforward application of the triangle
inequality.

\subsubsection{Exercise 9}
(a) If $f$ is differentiable at $a$, then we can let $g(x) = f(a) + f'(a) (x - a)$. For the other direction,
\begin{align*}
        \lim_{h \to 0} \frac{f(a + h) - a_0 - a_1h}{h} &= 0 \\
        \implies \lim_{h \to 0} \frac{f(a + h) - a_0}{h} &= a_1 \\
        \implies a_0 = f(a)
\end{align*}
so $f$ is differentiable at $a$.

(b) We can break up the $n^{\text{th}}$ order limit into
\begin{align*}
        \lim_{x \to  a} \frac{f(x) - g(x)}{(x - a)^n} &=
        \lim_{x \to a} \frac{f(x) - \sum_{i = 0}^{n - 1} \frac{f^{(i)}(a)}{i!} (x - a)^i}{(x - a)^n} +
        \frac{f^{(n)}(a)}{n!} \\
                                                      &= \frac{f^{(n)}(a)}{n!} - \frac{f^{(n)}(a)}{n!} = 0
\end{align*}
where the last step follows from repeated application of L'Hopital's.

\subsection{Basic Theorems}

\subsubsection{Exercise 11}
(a) Let $G$ be a function such that $G' = g$. Then
\begin{align*}
        f'(x, y) &= g(x + y) (\pi_1'(x, y) + \pi_2'(x, y)) \\
                 &= g(x + y) ((1, 0) + (0, 1)) = (g(x + y), g(x + y))
\end{align*}

(b) Following the setup of (a), we have
\begin{align*}
        f'(x, y) &= g(xy) (y \pi_1'(x, y) + x \pi_2'(x, y)) \\
                 &= g(xy) (y, x)
\end{align*}

\subsubsection{Exercise 12}
(a) Since $f(h, k) = hk f(1, 1)$, the desired result follows immediately from $\lim_{(h, k) \to 0} \frac{\abs{hk}}{\abs{(h, k)}} = 0$.

(b) We have that $f(a + h, b + k) - f(a, b) = f(a, k) + f(h, b) + f(h, k)$ from bilinearity, so $Df(a, b)(x, y) = f(a, y) + f(x, b)$ as
desired.

(c) The function $p: \mathbb{R} \times \mathbb{R} \to \mathbb{R}$ from Theorem 2-3 is bilinear, so it is just a special case
of (b).

\subsubsection{Exercise 14}
(a) We can bound the multilinear case with the bilinear case:
\begin{align*}
        \lim_{h \to 0} \frac{\abs{f(a_1, ..., h_i, ..., h_j, ..., a_k)}}{\abs{h}} &\leq
        \lim_{h \to 0} \frac{\abs{f(a_1, ..., h_i, ..., h_j, ..., a_k)}}{\abs{(h_i, h_j)}} \\ &\leq
        \lim_{(h_i, h_j) \to 0} \frac{\abs{f(a_1, ..., h_i, ..., h_j, ..., a_k)}}{\abs{(h_i, h_j)}} \\
                                                                                             &= 0
\end{align*}

(b) Expanding $f(a_1 + h_1, ..., a_n + h_n) - f(a_1, ..., a_n) - Df(a_1, ..., a_n)(h_1, ..., h_n)$
leaves only terms that are at least bilinear, so by part (a) we are done.

\subsubsection{Exercise 16}
Using the fact that $Dx = x$ (from Theorem 2-3), we have that
\begin{align*}
        f'(f^{-1}) \circ f^{-1\prime} (x) &= x \\
        \implies f^{-1\prime} (x) &= [f'(f^{-1} (x))]^{-1} 
\end{align*}

\subsection{Partial Derivatives}

\subsubsection{Exercise 19}
Since $f(1, y) = 1$, $D_2 f(1, y) = 0$.

\subsubsection{Exercise 21}
(a) The first term of $f$ is independent of $y$, so we need not consider it. Letting $G_2$ be the antiderivative of
$g_2$, we have that the second term is equivalent to $G_2(x, y) - G_2(x, 0)$. Differentiating this with respect to $y$
yields $g_2(x, y)$ as desired.

(b) Replacing the first integrand with $g_1(t, y)$ and the second integrand with $g_2(0, t)$ will give
$D_2 f(x, y) = g_1(x, y)$.

(c) The functions $f(x, y) = \frac{x^2}{2} + \frac{y^2}{2}$ and $f(x, y) = xy$ will work (obtained by integrating the
desired partial derivatives with respect to $x$ and $y$).

\subsubsection{Exercise 22}
Applying the mean value theorem to each variable gives the desired results.

\subsubsection{Exercise 23}
(a) Consider $(x_1, y_1)$ and $(x_2, y_2)$. Since $D_1 f = D_2 f = 0$, we have that $f$ is constant along the lines from
$(x_1, y_1)$ to $(-\epsilon, y_1)$, $(-\epsilon, y_1)$ to $(-\epsilon, y_2)$, and $(-\epsilon, y_2)$ to $(x_2, y_2)$ by
the logic of the previous exercise (where $\epsilon > 0$). Thus, $f(x_1, y_1) = f(x_2, y_2)$ for all $(x_1, y_1)$ and
$(x_2, y_2)$.

(b) Take the following function:
\begin{align*}
        f(x, y) = 
        \begin{cases}
                0 & x < 0 \\
                1 & x \geq 0, y > 0 \\
                -1 & x \geq 0, y < 0 \\
        \end{cases}
\end{align*}
This function is not independent of $y$, since $f(0, 1) \neq f(0, -1)$. However,
$D_2 f = 0$ (due to $x \geq 0, y = 0$ not being in $A$).

\subsubsection{Exercise 25}
Since $\exp(-x^{-2})$ is $C^\infty$ for all $x \neq 0$, $f$ is also $C^\infty$ for all such $x$. For
$x = 0$, we can proceed via L'Hopital's as suggested:
\begin{align*}
        f'(0) &= \lim_{h \to 0} \frac{f(h) - f(0)}{h} \\
              &= \lim_{h \to 0} \frac{\exp(-h^{-2})}{h} \\
              &= \lim_{h \to 0} \frac{\frac{1}{h}}{\exp(h^{-2})} \\
              &= \lim_{h \to 0} \frac{h}{2\exp(h^{-2})} \\
              &= 0
\end{align*}
Repeating this procedure indefinitely shows that $f^{(i)}(0) = 0$ and that $f$ is $C^\infty$.

\subsubsection{Exercise 26}
(a) The strategy from the previous exercise should work.

(b) Consider the following function:
\begin{align*}
        f(x) =
        \begin{cases}
                \exp(-x^{-2}) \exp(-(x - \epsilon)^{-2}) & x \in (0, \epsilon) \\
                0 & x \notin (0, \epsilon)
        \end{cases}
\end{align*}
Now we can define $g(x) = \int_{0}^{x} f / \int_{0}^{\epsilon} f$ as suggested. Since
$f(x) = 0$ for all $x \geq \epsilon$, we have that $\int_{0}^{x} f = \int_{0}^{\epsilon} f$.
Similarly, $\int_{0}^{x} f = 0$ for $x \leq 0$.

(c) The fact that $g$ is $C^\infty$ follows from $f$ being $C^\infty$. Similarly,
plugging $\frac{x_i - a_i}{\epsilon}$ into $f$ gives
$\exp(-\big(\frac{x_i - (a_i + \epsilon)}{\epsilon}\big)^{-2}) \exp(-\big(\frac{x_i - (a_i - \epsilon)}{\epsilon}\big)^{-2})$, from
which it can be seen that $f$ is positive only on 
$(a_1 - \epsilon, a_1 + \epsilon) \times ... \times (a_n - \epsilon, a_n + \epsilon)$
and 0 everywhere else.

(d) Since $C$ is compact and in $\mathbb{R}^n$, we can choose finitely many
closed rectangles around points in $C$ such that these rectangles are contained
in $A$ and their union covers $C$. For each such rectangle, we can then mimic
the style of the function $g$ in part (c) to produce a $C^\infty$ function that is 
non-zero only in that rectangle. Finally, we can take the sum of these functions
to get a function that is $C^\infty$ and positive on $C$ while being 0 outside of a
closed set contained in $A$.

(e) The function described in (d) satisfies $f(x) \geq \epsilon$ (for some $\epsilon > 0$)
for all $x \in C$ since $C$ is compact. Thus, we can consider $g \circ f$ with
the aforementioned $\epsilon$ ($g$ is described in (b)) to get the desired 
function.
